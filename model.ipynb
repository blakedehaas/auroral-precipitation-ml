{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxDEc4YBvlN-"
      },
      "source": [
        "Aurora Precipitation ML Notebook\n",
        "\n",
        "Problem: Unstable convergence\n",
        "\n",
        "Ideas:\n",
        "- [Works] Overfit to a single sample first\n",
        "- Increase network size\n",
        "  - Tried a 5 layer FF network, no improvement.\n",
        "- Huber loss (https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html)\n",
        "  - I don't think this will improve model performance\n",
        "- [Works] normalize (mean = 0, std dev = 1) all input features\n",
        "- [Works] Scale output features (log scale?)\n",
        "  - Applied log then followed by mean = 0, std dev = 1 on the log values\n",
        "- Make the model output a gaussian distribution as opposed to a single node. Loss is GaussianNLL (https://pytorch.org/docs/stable/generated/torch.nn.GaussianNLLLoss.html)\n",
        "  - This seems to work decently but I'm getting unstable training, have to debug this.\n",
        "- Output multiple gaussian distributions (mixture density network)\n",
        "- k-fold cross-validation\n",
        "(By using multiple training and testing cycles, it minimizes the risk of overfitting to a particular data split)\n",
        "- Look into ensemble of models with different initial conditions / handling of outliers\n",
        "(model ensembles are used a lot in ATOC research since systems are so chaotic)\n",
        "\n",
        "Things to do:\n",
        "- Split out the test set into its own TSV so it stays constant every run.\n",
        "(This wouldn't work with k-fold cross-validation)\n",
        "- Add one cycle LR scheduling\n",
        "- Filter the dataset according to Blake's suggestions\n",
        "- Increase dataloder workers to num cpus\n",
        "- Debug GaussianNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4mr26x9XlJPg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KqscDMaClU3p"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('data/train.tsv', sep='\\t')\n",
        "eval_df = pd.read_csv('data/validation.tsv', sep='\\t')\n",
        "train_df = train_df.sample(frac=0.1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Altitude</th>\n",
              "      <th>GCLAT</th>\n",
              "      <th>GCLON</th>\n",
              "      <th>ILAT</th>\n",
              "      <th>GLAT</th>\n",
              "      <th>GMLT</th>\n",
              "      <th>XXLAT</th>\n",
              "      <th>XXLON</th>\n",
              "      <th>Te1</th>\n",
              "      <th>Ne1</th>\n",
              "      <th>Pv1</th>\n",
              "      <th>I1</th>\n",
              "      <th>DateFormatted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1687.0</td>\n",
              "      <td>52.62</td>\n",
              "      <td>71.3</td>\n",
              "      <td>47.69</td>\n",
              "      <td>38.50</td>\n",
              "      <td>12.93</td>\n",
              "      <td>48.33</td>\n",
              "      <td>12.7</td>\n",
              "      <td>4274</td>\n",
              "      <td>1709</td>\n",
              "      <td>2.34</td>\n",
              "      <td>50</td>\n",
              "      <td>1997-06-03 07:59:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3623.0</td>\n",
              "      <td>-25.61</td>\n",
              "      <td>136.0</td>\n",
              "      <td>35.21</td>\n",
              "      <td>-1.50</td>\n",
              "      <td>15.32</td>\n",
              "      <td>999.00</td>\n",
              "      <td>999.0</td>\n",
              "      <td>4545</td>\n",
              "      <td>2348</td>\n",
              "      <td>2.34</td>\n",
              "      <td>51</td>\n",
              "      <td>1996-06-10 06:11:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3696.0</td>\n",
              "      <td>-56.81</td>\n",
              "      <td>10.0</td>\n",
              "      <td>55.17</td>\n",
              "      <td>-40.47</td>\n",
              "      <td>1.65</td>\n",
              "      <td>-54.46</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3502</td>\n",
              "      <td>1451</td>\n",
              "      <td>2.19</td>\n",
              "      <td>49</td>\n",
              "      <td>1997-05-22 01:57:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Altitude  GCLAT  GCLON   ILAT   GLAT   GMLT   XXLAT  XXLON   Te1   Ne1  \\\n",
              "0    1687.0  52.62   71.3  47.69  38.50  12.93   48.33   12.7  4274  1709   \n",
              "1    3623.0 -25.61  136.0  35.21  -1.50  15.32  999.00  999.0  4545  2348   \n",
              "2    3696.0 -56.81   10.0  55.17 -40.47   1.65  -54.46    1.5  3502  1451   \n",
              "\n",
              "    Pv1  I1       DateFormatted  \n",
              "0  2.34  50 1997-06-03 07:59:06  \n",
              "1  2.34  51 1996-06-10 06:11:04  \n",
              "2  2.19  49 1997-05-22 01:57:03  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Keep only specific columns\n",
        "columns_to_keep = ['Altitude', 'GCLAT', 'GCLON', 'ILAT', 'GLAT', 'GMLT', 'XXLAT', 'XXLON', 'Te1', 'Ne1', 'Pv1', 'I1', 'DateFormatted', 'TimeFormatted']\n",
        "train_df = train_df[columns_to_keep]\n",
        "eval_df = eval_df[columns_to_keep]\n",
        "\n",
        "# Convert DateFormatted and TimeFormatted columns to datetime\n",
        "train_df['DateFormatted'] = pd.to_datetime(train_df['DateFormatted'] + ' ' + train_df['TimeFormatted'], format='%Y-%m-%d %H:%M:%S')\n",
        "eval_df['DateFormatted'] = pd.to_datetime(eval_df['DateFormatted'] + ' ' + eval_df['TimeFormatted'], format='%Y-%m-%d %H:%M:%S')\n",
        "train_df.drop('TimeFormatted', axis=1, inplace=True)\n",
        "eval_df.drop('TimeFormatted', axis=1, inplace=True)\n",
        "\n",
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "CilXn9liwKBJ",
        "outputId": "a7f959fc-7db2-46ba-b649-3d4dbfbf5cee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized data shape: (420524, 13)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Altitude</th>\n",
              "      <th>GCLAT</th>\n",
              "      <th>GCLON</th>\n",
              "      <th>ILAT</th>\n",
              "      <th>GLAT</th>\n",
              "      <th>GMLT</th>\n",
              "      <th>XXLAT</th>\n",
              "      <th>XXLON</th>\n",
              "      <th>Te1</th>\n",
              "      <th>Ne1</th>\n",
              "      <th>Pv1</th>\n",
              "      <th>I1</th>\n",
              "      <th>DateFormatted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.409704</td>\n",
              "      <td>0.684502</td>\n",
              "      <td>-0.831158</td>\n",
              "      <td>-0.149552</td>\n",
              "      <td>0.786159</td>\n",
              "      <td>0.197250</td>\n",
              "      <td>-0.002200</td>\n",
              "      <td>-0.169951</td>\n",
              "      <td>-0.625576</td>\n",
              "      <td>-0.130394</td>\n",
              "      <td>-0.115919</td>\n",
              "      <td>0.484468</td>\n",
              "      <td>1997-06-03 07:59:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.650825</td>\n",
              "      <td>-0.910177</td>\n",
              "      <td>-0.222542</td>\n",
              "      <td>-0.350600</td>\n",
              "      <td>-0.317321</td>\n",
              "      <td>0.529998</td>\n",
              "      <td>5.409682</td>\n",
              "      <td>5.641005</td>\n",
              "      <td>-0.530749</td>\n",
              "      <td>-0.009025</td>\n",
              "      <td>-0.115919</td>\n",
              "      <td>0.538502</td>\n",
              "      <td>1996-06-10 06:11:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.622210</td>\n",
              "      <td>-1.546173</td>\n",
              "      <td>-1.407791</td>\n",
              "      <td>-0.029052</td>\n",
              "      <td>-1.392386</td>\n",
              "      <td>-1.373207</td>\n",
              "      <td>-0.587353</td>\n",
              "      <td>-0.235937</td>\n",
              "      <td>-0.895709</td>\n",
              "      <td>-0.179398</td>\n",
              "      <td>-0.362060</td>\n",
              "      <td>0.430434</td>\n",
              "      <td>1997-05-22 01:57:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Altitude     GCLAT     GCLON      ILAT      GLAT      GMLT     XXLAT  \\\n",
              "0 -1.409704  0.684502 -0.831158 -0.149552  0.786159  0.197250 -0.002200   \n",
              "1 -0.650825 -0.910177 -0.222542 -0.350600 -0.317321  0.529998  5.409682   \n",
              "2 -0.622210 -1.546173 -1.407791 -0.029052 -1.392386 -1.373207 -0.587353   \n",
              "\n",
              "      XXLON       Te1       Ne1       Pv1        I1       DateFormatted  \n",
              "0 -0.169951 -0.625576 -0.130394 -0.115919  0.484468 1997-06-03 07:59:06  \n",
              "1  5.641005 -0.530749 -0.009025 -0.115919  0.538502 1996-06-10 06:11:04  \n",
              "2 -0.235937 -0.895709 -0.179398 -0.362060  0.430434 1997-05-22 01:57:03  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Normalize all location and atmospheric parameters (mean = 0 and std dev = 1)\n",
        "columns_to_normalize = ['Altitude', 'GCLAT', 'GCLON', 'ILAT', 'GLAT', 'GMLT', 'XXLAT', 'XXLON', 'Ne1', 'Pv1', 'I1', 'Te1']\n",
        "\n",
        "# Function to calculate mean and std dev for specified columns\n",
        "def calculate_stats(df, columns):\n",
        "    means = df[columns].mean()\n",
        "    stds = df[columns].std()\n",
        "    return means, stds\n",
        "\n",
        "# Function to normalize specified columns in the DataFrame\n",
        "def normalize_df(df, means, stds, columns):\n",
        "    df[columns] = (df[columns] - means) / stds\n",
        "    return df\n",
        "\n",
        "# Calculate mean and std for the specified columns\n",
        "means, stds = calculate_stats(train_df, columns_to_normalize)\n",
        "train_df_norm = normalize_df(train_df, means, stds, columns_to_normalize)\n",
        "\n",
        "means, stds = calculate_stats(eval_df, columns_to_normalize)\n",
        "eval_df_norm = normalize_df(eval_df, means, stds, columns_to_normalize)\n",
        "\n",
        "# Verify there are no NaNs in the normalized DataFrame\n",
        "assert train_df_norm[columns_to_normalize].isna().sum().sum() == 0, \"NaN values found in normalized data\"\n",
        "assert eval_df_norm[columns_to_normalize].isna().sum().sum() == 0, \"NaN values found in normalized data\"\n",
        "\n",
        "print(\"Normalized data shape:\", train_df_norm.shape)\n",
        "train_df_norm.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cyclic features added to train and eval datasets.\n",
            "Train dataframe shape: (420524, 15)\n",
            "Eval dataframe shape: (100000, 15)\n",
            "New columns in train dataset: ['Altitude', 'GCLAT', 'GCLON', 'ILAT', 'GLAT', 'GMLT', 'XXLAT', 'XXLON', 'Te1', 'Ne1', 'Pv1', 'I1', 'Year', 'DayOfYear_sin', 'TimeOfDay_sin']\n",
            "New columns in eval dataset: ['Altitude', 'GCLAT', 'GCLON', 'ILAT', 'GLAT', 'GMLT', 'XXLAT', 'XXLON', 'Te1', 'Ne1', 'Pv1', 'I1', 'Year', 'DayOfYear_sin', 'TimeOfDay_sin']\n"
          ]
        }
      ],
      "source": [
        "# Convert date and time into cyclic features for both train and eval datasets\n",
        "for df in [train_df_norm, eval_df_norm]:\n",
        "    # Extract components from DateFormatted\n",
        "    df['Year'] = df['DateFormatted'].dt.year - 1989\n",
        "    df['DayOfYear'] = df['DateFormatted'].dt.dayofyear\n",
        "    df['TimeOfDay'] = (df['DateFormatted'].dt.hour * 3600 +\n",
        "                       df['DateFormatted'].dt.minute * 60 +\n",
        "                       df['DateFormatted'].dt.second) / 86400\n",
        "\n",
        "    # Calculate cyclic features\n",
        "    df['DayOfYear_sin'] = np.sin(2 * np.pi * df['DayOfYear'] / 365.25)\n",
        "    df['TimeOfDay_sin'] = np.sin(2 * np.pi * df['TimeOfDay'])\n",
        "\n",
        "# Drop original date column and intermediate columns\n",
        "train_df_norm_final = train_df_norm.drop(['DateFormatted', 'DayOfYear', 'TimeOfDay'], axis=1)\n",
        "eval_df_norm_final = eval_df_norm.drop(['DateFormatted', 'DayOfYear', 'TimeOfDay'], axis=1)\n",
        "\n",
        "print(\"Cyclic features added to train and eval datasets.\")\n",
        "print(\"Train dataframe shape:\", train_df_norm_final.shape)\n",
        "print(\"Eval dataframe shape:\", eval_df_norm_final.shape)\n",
        "print(\"New columns in train dataset:\", train_df_norm_final.columns.tolist())\n",
        "print(\"New columns in eval dataset:\", eval_df_norm_final.columns.tolist())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zevfLZ-s4JyH"
      },
      "outputs": [],
      "source": [
        "input_columns = ['Altitude', 'GCLAT', 'GCLON', 'ILAT', 'GLAT', 'GMLT', 'XXLAT', 'XXLON', 'Ne1', 'Pv1', 'I1', 'Year', 'DayOfYear_sin', 'TimeOfDay_sin']\n",
        "output_column = 'Te1'\n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, dataframe, input_columns, output_column):\n",
        "        self.X = torch.tensor(dataframe[input_columns].values, dtype=torch.float32)\n",
        "        self.y = torch.tensor(dataframe[output_column].values, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# class Network(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size, output_size):\n",
        "#         super(Network, self).__init__()\n",
        "#         self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "#         self.layer2 = nn.Linear(hidden_size, output_size)\n",
        "#         self.relu = nn.ReLU()\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.relu(self.layer1(x))\n",
        "#         x = self.layer2(x)\n",
        "#         return x\n",
        "\n",
        "class GaussianNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(GaussianNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.mean_layer = nn.Linear(hidden_size, output_size)\n",
        "        self.var_layer = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        mean = self.mean_layer(x)\n",
        "        var = self.relu(self.var_layer(x))\n",
        "        return mean, var\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 8\n",
        "\n",
        "# Set up data loader\n",
        "train_ds = DataFrameDataset(train_df_norm_final, input_columns, output_column)\n",
        "eval_ds = DataFrameDataset(eval_df_norm_final, input_columns, output_column)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "eval_loader = DataLoader(eval_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "# Initialize the model\n",
        "input_size = len(input_columns)\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "# model = Network(input_size, hidden_size, output_size).to(\"cuda\")\n",
        "model = GaussianNetwork(input_size, hidden_size, output_size).to(\"cuda\")\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# criterion = nn.MSELoss()\n",
        "criterion = nn.GaussianNLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hLwfcGROagC",
        "outputId": "d6643fee-9133-485e-bb83-e54173c2ddf6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 44/52566 [00:00<04:15, 205.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [0], Train Loss: 408821.1250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1072/52566 [00:02<02:01, 425.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [1000], Train Loss: 53714.6680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 2087/52566 [00:04<01:48, 465.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [2000], Train Loss: 0.0778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 3067/52566 [00:07<01:50, 448.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [3000], Train Loss: -0.1187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 4092/52566 [00:09<01:44, 462.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [4000], Train Loss: 0.4316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|▉         | 5045/52566 [00:11<01:41, 470.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [5000], Train Loss: -0.0562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 6070/52566 [00:13<01:40, 460.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [6000], Train Loss: -0.0344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 7068/52566 [00:15<01:40, 451.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [7000], Train Loss: 0.1463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 8080/52566 [00:18<01:43, 431.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [8000], Train Loss: -0.1321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 9064/52566 [00:20<01:32, 468.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [9000], Train Loss: 0.8534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 10047/52566 [00:22<01:37, 434.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [10000], Train Loss: 0.1093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 10817/52566 [00:24<01:33, 446.27it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m mean, var \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(mean, y, var)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m print_every \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (total_steps \u001b[38;5;241m%\u001b[39m print_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m total_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
            "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[14], line 37\u001b[0m, in \u001b[0;36mGaussianNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 37\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_layer(x)\n\u001b[1;32m     39\u001b[0m     var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_layer(x))\n",
            "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torch/nn/modules/activation.py:103\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torch/nn/functional.py:1500\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, data_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(data_loader):\n",
        "            x = x.to(\"cuda\")\n",
        "            y = y.to(\"cuda\")\n",
        "            # outputs = model(x)\n",
        "            # loss = criterion(outputs, y)\n",
        "            mean, var = model(x)\n",
        "            loss = criterion(mean, y, var)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 30\n",
        "eval_every = 1\n",
        "print_every = 1000\n",
        "\n",
        "total_steps = 0\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    for x, y in tqdm(train_loader):\n",
        "        x = x.to(\"cuda\")\n",
        "        y = y.to(\"cuda\")\n",
        "\n",
        "        # Forward pass\n",
        "        mean, var = model(x)\n",
        "        loss = criterion(mean, y, var)\n",
        "\n",
        "        # TODO: Investigate why loss is negative\n",
        "\n",
        "        if print_every is not None and (total_steps % print_every == 0 or total_steps == 0):\n",
        "            print(f'Step [{total_steps}], Train Loss: {loss.item():.4f}')\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        total_steps += 1\n",
        "\n",
        "    if (epoch + 1) % eval_every == 0:\n",
        "        test_loss = evaluate_model(model, test_loader, criterion)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Avg Train Loss: {epoch_loss/len(train_loader):.4f}, Test Loss: {test_loss:.4f}')\n",
        "\n",
        "\n",
        "print('Training finished!')\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'simple_ff_model.pth')\n",
        "\n",
        "# Final evaluation\n",
        "final_test_loss = evaluate_model(model, test_loader, criterion)\n",
        "print(f'Final Test MSE: {final_test_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fovbv-QcPC-2",
        "outputId": "45c77601-257a-4ef4-c4c1-5a525350e0e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y: 7424.000062457462\n",
            "Prediction 4366.337213231267\n",
            "y: 4553.000006766773\n",
            "Prediction 7920.859834885141\n",
            "y: 5507.999999886252\n",
            "Prediction 5091.6168122874815\n",
            "y: 7440.000091077357\n",
            "Prediction 9133.70495691905\n",
            "y: 4809.999999881303\n",
            "Prediction 3826.4774407709324\n",
            "y: 4809.999999881303\n",
            "Prediction 6629.711670381693\n"
          ]
        }
      ],
      "source": [
        "# Inference code\n",
        "\n",
        "# TODO: Create a benchmark (percentage accuracy) to validate model is not overfitting\n",
        "inference_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "def unnormalize_target(pred, target_mean, target_std):\n",
        "    pred = np.exp(pred * target_std + target_mean)\n",
        "    return pred\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, (x, y) in enumerate(inference_loader):\n",
        "        x = x.to(\"cuda\")\n",
        "        y = y.to(\"cuda\")\n",
        "        # print(\"x:\", x)\n",
        "        print(\"y:\", unnormalize_target(y.item(), target_mean, target_std))\n",
        "        mean, var = model(x)\n",
        "        print(\"Prediction\", unnormalize_target(mean.item(), target_mean, target_std))\n",
        "        if idx > 4:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jN61yLs5ZstJ"
      },
      "outputs": [],
      "source": [
        "# Suppose that within +-10% of actual value is a sucess\n",
        "\n",
        "# TODO: Plot the loss to visualize overfitting\n",
        "# TODO: Save each model to Google Drive for benchmarking later\n",
        "# TODO: Create a polar visualization in order to compare each model to the next one\n",
        "# TODO: Creat metrics to compare each model to the next one\n",
        "# TODO: Remove normalization and compare to normalized model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_Bmn8cpoVbHV",
        "outputId": "8f741a66-efe1-449c-a18d-033a59fd0a86"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/30], Avg Train Loss: 0.4040, Test Loss: 0.1765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/30], Avg Train Loss: 0.5770, Test Loss: 0.0990\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/30], Avg Train Loss: 0.8843, Test Loss: 0.0427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/30], Avg Train Loss: 0.2812, Test Loss: 0.0085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/30], Avg Train Loss: 0.2589, Test Loss: -0.0139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/30], Avg Train Loss: 0.2444, Test Loss: -0.0356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/30], Avg Train Loss: 0.2865, Test Loss: -0.0415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/30], Avg Train Loss: 0.5262, Test Loss: -0.0642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/30], Avg Train Loss: 0.2058, Test Loss: -0.0772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/30], Avg Train Loss: 0.1906, Test Loss: -0.0902\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/30], Avg Train Loss: 0.2368, Test Loss: -0.0833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/30], Avg Train Loss: 0.2752, Test Loss: -0.0973\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/30], Avg Train Loss: 0.1495, Test Loss: -0.1232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/30], Avg Train Loss: 0.1182, Test Loss: -0.1232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/30], Avg Train Loss: 0.4029, Test Loss: -0.1190\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [16/30], Avg Train Loss: 0.2002, Test Loss: -0.1482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/30], Avg Train Loss: 0.1518, Test Loss: -0.1395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [18/30], Avg Train Loss: 0.2024, Test Loss: -0.1566\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [19/30], Avg Train Loss: 0.1048, Test Loss: -0.1584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [20/30], Avg Train Loss: 0.1146, Test Loss: -0.1705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [21/30], Avg Train Loss: 0.1021, Test Loss: -0.1773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [22/30], Avg Train Loss: 0.0907, Test Loss: -0.1634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [23/30], Avg Train Loss: 0.0362, Test Loss: -0.1831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [24/30], Avg Train Loss: 0.1133, Test Loss: -0.1938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [25/30], Avg Train Loss: 0.0365, Test Loss: -0.2039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [26/30], Avg Train Loss: 0.0173, Test Loss: -0.2039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [27/30], Avg Train Loss: 0.1619, Test Loss: -0.2271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [28/30], Avg Train Loss: 0.0940, Test Loss: -0.2116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [29/30], Avg Train Loss: 0.0660, Test Loss: -0.2239\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [30/30], Avg Train Loss: 0.0424, Test Loss: -0.2292\n",
            "Training finished!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Test MSE: -0.2292\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Updated Model Architecture\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming df_normalized, input_columns, and output_column are defined\n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, dataframe, input_columns, output_column):\n",
        "        self.X = torch.tensor(dataframe[input_columns].values, dtype=torch.float32)\n",
        "        self.y = torch.tensor(dataframe[output_column].values, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "class ImprovedGaussianNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, dropout_prob=0.5):\n",
        "        super(ImprovedGaussianNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, hidden_size)  # Additional hidden layer\n",
        "        self.mean_layer = nn.Linear(hidden_size, output_size)\n",
        "        self.var_layer = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softplus = nn.Softplus()\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.dropout(x)\n",
        "        mean = self.mean_layer(x)\n",
        "        var = self.softplus(self.var_layer(x)) + 1e-6  # Add epsilon to prevent zero variance\n",
        "        return mean, var\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 8\n",
        "input_size = len(input_columns)\n",
        "hidden_size = 128  # Increased hidden size\n",
        "output_size = 1\n",
        "num_epochs = 30\n",
        "learning_rate = 3e-4\n",
        "weight_decay = 1e-5  # L2 regularization parameter\n",
        "clip_value = 1.0  # For gradient clipping\n",
        "dropout_prob = 0.5  # Dropout probability\n",
        "\n",
        "# Set up data loader\n",
        "dataset = DataFrameDataset(df_normalized, input_columns, output_column)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train_size = int(0.9 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "# Initialize the model\n",
        "model = ImprovedGaussianNetwork(input_size, hidden_size, output_size, dropout_prob=dropout_prob).to(\"cuda\")\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.GaussianNLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(data_loader, leave=False):\n",
        "            x = x.to(\"cuda\")\n",
        "            y = y.to(\"cuda\")\n",
        "            mean, var = model(x)\n",
        "            loss = criterion(mean, y, var)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "# Training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "total_steps = 0\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    for x, y in tqdm(train_loader, leave=False):\n",
        "        x = x.to(\"cuda\")\n",
        "        y = y.to(\"cuda\")\n",
        "\n",
        "        # Forward pass\n",
        "        mean, var = model(x)\n",
        "        loss = criterion(mean, y, var)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        total_steps += 1\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_loss = evaluate_model(model, test_loader, criterion)\n",
        "    avg_train_loss = epoch_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    val_losses.append(test_loss)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Avg Train Loss: {avg_train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
        "\n",
        "print('Training finished!')\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'improved_gaussian_model_with_dropout.pth')\n",
        "\n",
        "# Final evaluation\n",
        "final_test_loss = evaluate_model(model, test_loader, criterion)\n",
        "print(f'Final Test MSE: {final_test_loss:.4f}')\n",
        "\n",
        "# Plotting the training and validation loss\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
        "plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "oNItT24eUdlQ",
        "outputId": "a3979a62-4e71-4307-c81f-50cedbe524e6"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e07d88f39d38>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Updated Model Architecture with Hyperparameter Tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Updated Model Architecture with Hyperparameter Tuning Using Optuna\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optuna\n",
        "\n",
        "# Assuming df_normalized, input_columns, and output_column are defined\n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, dataframe, input_columns, output_column):\n",
        "        self.X = torch.tensor(dataframe[input_columns].values, dtype=torch.float32)\n",
        "        self.y = torch.tensor(dataframe[output_column].values, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "class ImprovedGaussianNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, dropout_prob=0.5, activation='relu'):\n",
        "        super(ImprovedGaussianNetwork, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(input_size, hidden_size))\n",
        "        if activation == 'relu':\n",
        "            layers.append(nn.ReLU())\n",
        "        elif activation == 'leakyrelu':\n",
        "            layers.append(nn.LeakyReLU())\n",
        "        elif activation == 'elu':\n",
        "            layers.append(nn.ELU())\n",
        "        layers.append(nn.Dropout(p=dropout_prob))\n",
        "        for _ in range(num_layers - 1):\n",
        "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "            if activation == 'relu':\n",
        "                layers.append(nn.ReLU())\n",
        "            elif activation == 'leakyrelu':\n",
        "                layers.append(nn.LeakyReLU())\n",
        "            elif activation == 'elu':\n",
        "                layers.append(nn.ELU())\n",
        "            layers.append(nn.Dropout(p=dropout_prob))\n",
        "        self.hidden_layers = nn.Sequential(*layers)\n",
        "        self.mean_layer = nn.Linear(hidden_size, output_size)\n",
        "        self.var_layer = nn.Linear(hidden_size, output_size)\n",
        "        self.softplus = nn.Softplus()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden_layers(x)\n",
        "        mean = self.mean_layer(x)\n",
        "        var = self.softplus(self.var_layer(x)) + 1e-6  # Prevent zero variance\n",
        "        return mean, var\n",
        "\n",
        "def objective(trial):\n",
        "    # Hyperparameters to tune\n",
        "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
        "    hidden_size = trial.suggest_categorical('hidden_size', [64, 128, 256])\n",
        "    dropout_prob = trial.suggest_uniform('dropout_prob', 0.1, 0.5)\n",
        "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
        "    num_layers = trial.suggest_int('num_layers', 1, 4)\n",
        "    activation = trial.suggest_categorical('activation', ['relu', 'leakyrelu', 'elu'])\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Set up the dataset\n",
        "    dataset = DataFrameDataset(df_normalized, input_columns, output_column)\n",
        "    dataset_size = len(dataset)\n",
        "    n_splits = 5  # Number of folds for cross-validation\n",
        "    fold_size = dataset_size // n_splits\n",
        "    indices = np.arange(dataset_size)\n",
        "\n",
        "    fold_mses = []\n",
        "    fold_r2s = []\n",
        "\n",
        "    for fold in range(n_splits):\n",
        "        # Time series split\n",
        "        val_start = fold * fold_size\n",
        "        val_end = val_start + fold_size\n",
        "        train_indices = indices[:val_end]\n",
        "        val_indices = indices[val_end:val_end + fold_size] if val_end + fold_size <= dataset_size else indices[val_end:]\n",
        "\n",
        "        train_subset = Subset(dataset, train_indices)\n",
        "        val_subset = Subset(dataset, val_indices)\n",
        "\n",
        "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=False)\n",
        "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        # Initialize the model\n",
        "        model = ImprovedGaussianNetwork(len(input_columns), hidden_size, 1, num_layers=num_layers, dropout_prob=dropout_prob, activation=activation).to(device)\n",
        "\n",
        "        # Define loss function, optimizer, and scheduler\n",
        "        criterion = nn.GaussianNLLLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5, verbose=False)\n",
        "\n",
        "        # Early stopping variables\n",
        "        best_val_loss = float('inf')\n",
        "        epochs_no_improve = 0\n",
        "        patience = 10  # Early stopping patience\n",
        "        num_epochs = 50  # Reduced for faster trials\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            total_train_loss = 0\n",
        "            for x, y in train_loader:\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                mean, var = model(x)\n",
        "                loss = criterion(mean, y, var)\n",
        "\n",
        "                # Backward pass and optimize\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "            avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "            # Validation\n",
        "            model.eval()\n",
        "            total_val_loss = 0\n",
        "            preds = []\n",
        "            trues = []\n",
        "            with torch.no_grad():\n",
        "                for x, y in val_loader:\n",
        "                    x = x.to(device)\n",
        "                    y = y.to(device)\n",
        "                    mean, var = model(x)\n",
        "                    loss = criterion(mean, y, var)\n",
        "                    total_val_loss += loss.item()\n",
        "                    preds.extend(mean.cpu().numpy())\n",
        "                    trues.extend(y.cpu().numpy())\n",
        "            avg_val_loss = total_val_loss / len(val_loader)\n",
        "            mse = mean_squared_error(trues, preds)\n",
        "            r2 = r2_score(trues, preds)\n",
        "\n",
        "            # Scheduler step\n",
        "            scheduler.step(avg_val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if avg_val_loss < best_val_loss:\n",
        "                best_val_loss = avg_val_loss\n",
        "                epochs_no_improve = 0\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "                if epochs_no_improve >= patience:\n",
        "                    break\n",
        "\n",
        "        # Record metrics for the fold\n",
        "        fold_mses.append(mse)\n",
        "        fold_r2s.append(r2)\n",
        "\n",
        "    # Return the average MSE across folds\n",
        "    avg_mse = np.mean(fold_mses)\n",
        "    return avg_mse\n",
        "\n",
        "# Create a study and optimize\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print('Best hyperparameters:', study.best_params)\n",
        "\n",
        "# Train final model with best hyperparameters\n",
        "best_params = study.best_params\n",
        "lr = best_params['lr']\n",
        "hidden_size = best_params['hidden_size']\n",
        "dropout_prob = best_params['dropout_prob']\n",
        "weight_decay = best_params['weight_decay']\n",
        "batch_size = best_params['batch_size']\n",
        "num_layers = best_params['num_layers']\n",
        "activation = best_params['activation']\n",
        "\n",
        "# You can now train your final model using these hyperparameters\n",
        "# and evaluate its performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pQ1ZeAtmYnuo"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
