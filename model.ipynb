{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxDEc4YBvlN-"
      },
      "source": [
        "Aurora Precipitation ML Notebook\n",
        "\n",
        "Problem: Unstable convergence\n",
        "\n",
        "Ideas:\n",
        "- [Works] Overfit to a single sample first\n",
        "- Increase network size\n",
        "  - Tried a 5 layer FF network, no improvement.\n",
        "- Huber loss (https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html)\n",
        "  - I don't think this will improve model performance\n",
        "- [Works] normalize (mean = 0, std dev = 1) all input features\n",
        "- [Works] Scale output features (log scale?)\n",
        "  - Applied log then followed by mean = 0, std dev = 1 on the log values\n",
        "- Make the model output a gaussian distribution as opposed to a single node. Loss is GaussianNLL (https://pytorch.org/docs/stable/generated/torch.nn.GaussianNLLLoss.html)\n",
        "  - This seems to work decently but I'm getting unstable training, have to debug this.\n",
        "- Output multiple gaussian distributions (mixture density network)\n",
        "- k-fold cross-validation\n",
        "(By using multiple training and testing cycles, it minimizes the risk of overfitting to a particular data split)\n",
        "- Look into ensemble of models with different initial conditions / handling of outliers\n",
        "(model ensembles are used a lot in ATOC research since systems are so chaotic)\n",
        "\n",
        "Things to do:\n",
        "- Split out the test set into its own TSV so it stays constant every run.\n",
        "(This wouldn't work with k-fold cross-validation)\n",
        "- Add one cycle LR scheduling\n",
        "- Filter the dataset according to Blake's suggestions\n",
        "- Increase dataloder workers to num cpus\n",
        "- Debug GaussianNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4mr26x9XlJPg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KqscDMaClU3p"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('data/train.tsv', sep='\\t')\n",
        "eval_df = pd.read_csv('data/validation.tsv', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Altitude</th>\n",
              "      <th>GCLAT</th>\n",
              "      <th>GCLON</th>\n",
              "      <th>ILAT</th>\n",
              "      <th>GLAT</th>\n",
              "      <th>GMLT</th>\n",
              "      <th>XXLAT</th>\n",
              "      <th>XXLON</th>\n",
              "      <th>Te1</th>\n",
              "      <th>Ne1</th>\n",
              "      <th>Pv1</th>\n",
              "      <th>I1</th>\n",
              "      <th>DateFormatted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2057.0</td>\n",
              "      <td>-17.46</td>\n",
              "      <td>101.6</td>\n",
              "      <td>25.49</td>\n",
              "      <td>-1.60</td>\n",
              "      <td>16.88</td>\n",
              "      <td>999.00</td>\n",
              "      <td>999.0</td>\n",
              "      <td>3819</td>\n",
              "      <td>2371</td>\n",
              "      <td>2.03</td>\n",
              "      <td>59</td>\n",
              "      <td>1995-10-13 09:50:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7442.0</td>\n",
              "      <td>50.49</td>\n",
              "      <td>347.8</td>\n",
              "      <td>49.87</td>\n",
              "      <td>18.86</td>\n",
              "      <td>17.82</td>\n",
              "      <td>48.51</td>\n",
              "      <td>17.8</td>\n",
              "      <td>7041</td>\n",
              "      <td>2199</td>\n",
              "      <td>2.19</td>\n",
              "      <td>40</td>\n",
              "      <td>1991-12-02 17:51:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>377.0</td>\n",
              "      <td>-75.07</td>\n",
              "      <td>197.9</td>\n",
              "      <td>72.41</td>\n",
              "      <td>-71.48</td>\n",
              "      <td>22.93</td>\n",
              "      <td>-72.40</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2227</td>\n",
              "      <td>92216</td>\n",
              "      <td>2.66</td>\n",
              "      <td>107</td>\n",
              "      <td>1990-04-29 07:20:50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Altitude  GCLAT  GCLON   ILAT   GLAT   GMLT   XXLAT  XXLON   Te1    Ne1  \\\n",
              "0    2057.0 -17.46  101.6  25.49  -1.60  16.88  999.00  999.0  3819   2371   \n",
              "1    7442.0  50.49  347.8  49.87  18.86  17.82   48.51   17.8  7041   2199   \n",
              "2     377.0 -75.07  197.9  72.41 -71.48  22.93  -72.40    0.2  2227  92216   \n",
              "\n",
              "    Pv1   I1       DateFormatted  \n",
              "0  2.03   59 1995-10-13 09:50:54  \n",
              "1  2.19   40 1991-12-02 17:51:01  \n",
              "2  2.66  107 1990-04-29 07:20:50  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Keep only specific columns\n",
        "columns_to_keep = ['Altitude', 'GCLAT', 'GCLON', 'ILAT', 'GLAT', 'GMLT', 'XXLAT', 'XXLON', 'Te1', 'Ne1', 'Pv1', 'I1', 'DateFormatted', 'TimeFormatted']\n",
        "train_df = train_df[columns_to_keep]\n",
        "eval_df = eval_df[columns_to_keep]\n",
        "\n",
        "# Convert DateFormatted and TimeFormatted columns to datetime\n",
        "train_df['DateFormatted'] = pd.to_datetime(train_df['DateFormatted'] + ' ' + train_df['TimeFormatted'], format='%Y-%m-%d %H:%M:%S')\n",
        "eval_df['DateFormatted'] = pd.to_datetime(eval_df['DateFormatted'] + ' ' + eval_df['TimeFormatted'], format='%Y-%m-%d %H:%M:%S')\n",
        "train_df.drop('TimeFormatted', axis=1, inplace=True)\n",
        "eval_df.drop('TimeFormatted', axis=1, inplace=True)\n",
        "\n",
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "CilXn9liwKBJ",
        "outputId": "a7f959fc-7db2-46ba-b649-3d4dbfbf5cee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized data shape: (4205241, 13)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Altitude</th>\n",
              "      <th>GCLAT</th>\n",
              "      <th>GCLON</th>\n",
              "      <th>ILAT</th>\n",
              "      <th>GLAT</th>\n",
              "      <th>GMLT</th>\n",
              "      <th>XXLAT</th>\n",
              "      <th>XXLON</th>\n",
              "      <th>Te1</th>\n",
              "      <th>Ne1</th>\n",
              "      <th>Pv1</th>\n",
              "      <th>I1</th>\n",
              "      <th>DateFormatted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.265549</td>\n",
              "      <td>-0.747445</td>\n",
              "      <td>-0.545132</td>\n",
              "      <td>-0.505899</td>\n",
              "      <td>-0.322701</td>\n",
              "      <td>0.743981</td>\n",
              "      <td>5.417435</td>\n",
              "      <td>5.649236</td>\n",
              "      <td>-0.784141</td>\n",
              "      <td>-0.005524</td>\n",
              "      <td>-0.624553</td>\n",
              "      <td>0.970495</td>\n",
              "      <td>1995-10-13 09:50:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.844787</td>\n",
              "      <td>0.639735</td>\n",
              "      <td>1.774402</td>\n",
              "      <td>-0.114229</td>\n",
              "      <td>0.242768</td>\n",
              "      <td>0.874721</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.139710</td>\n",
              "      <td>0.343766</td>\n",
              "      <td>-0.036200</td>\n",
              "      <td>-0.361635</td>\n",
              "      <td>-0.056877</td>\n",
              "      <td>1991-12-02 17:51:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.923927</td>\n",
              "      <td>-1.923536</td>\n",
              "      <td>0.362143</td>\n",
              "      <td>0.247882</td>\n",
              "      <td>-2.254030</td>\n",
              "      <td>1.585443</td>\n",
              "      <td>-0.690566</td>\n",
              "      <td>-0.243547</td>\n",
              "      <td>-1.341443</td>\n",
              "      <td>16.018045</td>\n",
              "      <td>0.410687</td>\n",
              "      <td>3.565963</td>\n",
              "      <td>1990-04-29 07:20:50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Altitude     GCLAT     GCLON      ILAT      GLAT      GMLT     XXLAT  \\\n",
              "0 -1.265549 -0.747445 -0.545132 -0.505899 -0.322701  0.743981  5.417435   \n",
              "1  0.844787  0.639735  1.774402 -0.114229  0.242768  0.874721 -0.001264   \n",
              "2 -1.923927 -1.923536  0.362143  0.247882 -2.254030  1.585443 -0.690566   \n",
              "\n",
              "      XXLON       Te1        Ne1       Pv1        I1       DateFormatted  \n",
              "0  5.649236 -0.784141  -0.005524 -0.624553  0.970495 1995-10-13 09:50:54  \n",
              "1 -0.139710  0.343766  -0.036200 -0.361635 -0.056877 1991-12-02 17:51:01  \n",
              "2 -0.243547 -1.341443  16.018045  0.410687  3.565963 1990-04-29 07:20:50  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Normalize all location and atmospheric parameters (mean = 0 and std dev = 1)\n",
        "columns_to_normalize = ['Altitude', 'GCLAT', 'GCLON', 'ILAT', 'GLAT', 'GMLT', 'XXLAT', 'XXLON', 'Ne1', 'Pv1', 'I1', 'Te1']\n",
        "\n",
        "# Function to calculate mean and std dev for specified columns\n",
        "def calculate_stats(df, columns):\n",
        "    means = df[columns].mean()\n",
        "    stds = df[columns].std()\n",
        "    return means, stds\n",
        "\n",
        "# Function to normalize specified columns in the DataFrame\n",
        "def normalize_df(df, means, stds, columns):\n",
        "    df[columns] = (df[columns] - means) / stds\n",
        "    return df\n",
        "\n",
        "# Calculate mean and std for the specified columns\n",
        "means, stds = calculate_stats(train_df, columns_to_normalize)\n",
        "train_df_norm = normalize_df(train_df, means, stds, columns_to_normalize)\n",
        "\n",
        "means, stds = calculate_stats(eval_df, columns_to_normalize)\n",
        "eval_df_norm = normalize_df(eval_df, means, stds, columns_to_normalize)\n",
        "\n",
        "# Verify there are no NaNs in the normalized DataFrame\n",
        "assert train_df_norm[columns_to_normalize].isna().sum().sum() == 0, \"NaN values found in normalized data\"\n",
        "assert eval_df_norm[columns_to_normalize].isna().sum().sum() == 0, \"NaN values found in normalized data\"\n",
        "\n",
        "print(\"Normalized data shape:\", train_df_norm.shape)\n",
        "train_df_norm.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cyclic features added to train and eval datasets.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Altitude</th>\n",
              "      <th>GCLAT</th>\n",
              "      <th>GCLON</th>\n",
              "      <th>ILAT</th>\n",
              "      <th>GLAT</th>\n",
              "      <th>GMLT</th>\n",
              "      <th>XXLAT</th>\n",
              "      <th>XXLON</th>\n",
              "      <th>Te1</th>\n",
              "      <th>Ne1</th>\n",
              "      <th>Pv1</th>\n",
              "      <th>I1</th>\n",
              "      <th>Year</th>\n",
              "      <th>DayOfYear_sin</th>\n",
              "      <th>TimeOfDay_sin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.265549</td>\n",
              "      <td>-0.747445</td>\n",
              "      <td>-0.545132</td>\n",
              "      <td>-0.505899</td>\n",
              "      <td>-0.322701</td>\n",
              "      <td>0.743981</td>\n",
              "      <td>5.417435</td>\n",
              "      <td>5.649236</td>\n",
              "      <td>-0.784141</td>\n",
              "      <td>-0.005524</td>\n",
              "      <td>-0.624553</td>\n",
              "      <td>0.970495</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.978548</td>\n",
              "      <td>0.533983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.844787</td>\n",
              "      <td>0.639735</td>\n",
              "      <td>1.774402</td>\n",
              "      <td>-0.114229</td>\n",
              "      <td>0.242768</td>\n",
              "      <td>0.874721</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.139710</td>\n",
              "      <td>0.343766</td>\n",
              "      <td>-0.036200</td>\n",
              "      <td>-0.361635</td>\n",
              "      <td>-0.056877</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.482206</td>\n",
              "      <td>-0.999232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.923927</td>\n",
              "      <td>-1.923536</td>\n",
              "      <td>0.362143</td>\n",
              "      <td>0.247882</td>\n",
              "      <td>-2.254030</td>\n",
              "      <td>1.585443</td>\n",
              "      <td>-0.690566</td>\n",
              "      <td>-0.243547</td>\n",
              "      <td>-1.341443</td>\n",
              "      <td>16.018045</td>\n",
              "      <td>0.410687</td>\n",
              "      <td>3.565963</td>\n",
              "      <td>1</td>\n",
              "      <td>0.888701</td>\n",
              "      <td>0.938443</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Altitude     GCLAT     GCLON      ILAT      GLAT      GMLT     XXLAT  \\\n",
              "0 -1.265549 -0.747445 -0.545132 -0.505899 -0.322701  0.743981  5.417435   \n",
              "1  0.844787  0.639735  1.774402 -0.114229  0.242768  0.874721 -0.001264   \n",
              "2 -1.923927 -1.923536  0.362143  0.247882 -2.254030  1.585443 -0.690566   \n",
              "\n",
              "      XXLON       Te1        Ne1       Pv1        I1  Year  DayOfYear_sin  \\\n",
              "0  5.649236 -0.784141  -0.005524 -0.624553  0.970495     6      -0.978548   \n",
              "1 -0.139710  0.343766  -0.036200 -0.361635 -0.056877     2      -0.482206   \n",
              "2 -0.243547 -1.341443  16.018045  0.410687  3.565963     1       0.888701   \n",
              "\n",
              "   TimeOfDay_sin  \n",
              "0       0.533983  \n",
              "1      -0.999232  \n",
              "2       0.938443  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert date/time into cyclic features for both train and eval datasets\n",
        "for df in [train_df_norm, eval_df_norm]:\n",
        "    # Extract components from DateFormatted\n",
        "    df['Year'] = df['DateFormatted'].dt.year - 1989\n",
        "    df['DayOfYear'] = df['DateFormatted'].dt.dayofyear\n",
        "    df['TimeOfDay'] = (df['DateFormatted'].dt.hour * 3600 +\n",
        "                       df['DateFormatted'].dt.minute * 60 +\n",
        "                       df['DateFormatted'].dt.second) / 86400\n",
        "\n",
        "    # Calculate cyclic features\n",
        "    df['DayOfYear_sin'] = np.sin(2 * np.pi * df['DayOfYear'] / 365.25)\n",
        "    df['TimeOfDay_sin'] = np.sin(2 * np.pi * df['TimeOfDay'])\n",
        "\n",
        "# Drop original date column and intermediate columns\n",
        "train_df_norm_final = train_df_norm.drop(['DateFormatted', 'DayOfYear', 'TimeOfDay'], axis=1)\n",
        "eval_df_norm_final = eval_df_norm.drop(['DateFormatted', 'DayOfYear', 'TimeOfDay'], axis=1)\n",
        "\n",
        "print(\"Cyclic features added to train and eval datasets.\")\n",
        "train_df_norm_final.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "zevfLZ-s4JyH"
      },
      "outputs": [],
      "source": [
        "input_columns = ['Altitude', 'GCLAT', 'GCLON', 'ILAT', 'GLAT', 'GMLT', 'XXLAT', 'XXLON', 'Ne1', 'Pv1', 'I1', 'Year', 'DayOfYear_sin', 'TimeOfDay_sin']\n",
        "output_column = 'Te1'\n",
        "model_name = 'tf_1'\n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, dataframe, input_columns, output_column):\n",
        "        self.X = torch.tensor(dataframe[input_columns].values, dtype=torch.float32)\n",
        "        self.y = torch.tensor(dataframe[output_column].values, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "class Network(nn.Module): # ff_1\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Network, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.layer2(x)\n",
        "        return x\n",
        "\n",
        "class FF_2Network(nn.Module): # ff_2\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(FF_2Network, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.layer_norm1 = nn.LayerNorm(hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, hidden_size * 2)\n",
        "        self.layer_norm2 = nn.LayerNorm(hidden_size * 2)\n",
        "        self.layer3 = nn.Linear(hidden_size * 2, hidden_size * 4)\n",
        "        self.layer_norm3 = nn.LayerNorm(hidden_size * 4)\n",
        "        self.layer4 = nn.Linear(hidden_size * 4, hidden_size * 2)\n",
        "        self.layer_norm4 = nn.LayerNorm(hidden_size * 2)\n",
        "        self.layer5 = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.layer_norm5 = nn.LayerNorm(hidden_size)\n",
        "        self.layer6 = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First block\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Second block\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Third block\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer_norm3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Fourth block\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer_norm4(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Fifth block\n",
        "        x = self.layer5(x)\n",
        "        x = self.layer_norm5(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Output layer\n",
        "        x = self.layer6(x)\n",
        "        return x\n",
        "\n",
        "class TransformerRegressor(nn.Module): # tf_1\n",
        "    def __init__(self, input_size, hidden_size=256, num_layers=4, num_heads=8, output_size=1, dropout=0.1):\n",
        "        super(TransformerRegressor, self).__init__()\n",
        "        self.linear = nn.Linear(1, hidden_size)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_size,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=hidden_size * 4,\n",
        "            dropout=dropout,\n",
        "            activation='relu',\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "        self.fc1 = nn.Linear(hidden_size * input_size, hidden_size * 4)\n",
        "        self.fc2 = nn.Linear(hidden_size * 4, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "        self.layer_norm1 = nn.LayerNorm(hidden_size * 4)\n",
        "        self.layer_norm2 = nn.LayerNorm(hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(-1)\n",
        "        x = self.linear(x)  # Add sequence dimension\n",
        "        x = self.dropout(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x.reshape(x.size(0), -1)  # Flatten the output\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class GaussianNetwork(nn.Module): # gaussian_1\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(GaussianNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.mean_layer = nn.Linear(hidden_size, output_size)\n",
        "        self.var_layer = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        mean = self.mean_layer(x)\n",
        "        var = self.relu(self.var_layer(x))\n",
        "        return mean, var\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 1024\n",
        "num_epochs = 1\n",
        "max_lr = 3e-4\n",
        "min_lr = 1e-5\n",
        "\n",
        "# Set up data loader\n",
        "train_ds = DataFrameDataset(train_df_norm_final, input_columns, output_column)\n",
        "eval_ds = DataFrameDataset(eval_df_norm_final, input_columns, output_column)\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "eval_loader = DataLoader(eval_ds, batch_size=batch_size, shuffle=False, num_workers=8)\n",
        "\n",
        "# Initialize the model\n",
        "input_size = len(input_columns)\n",
        "hidden_size = 2048\n",
        "output_size = 1\n",
        "# model = Network(input_size, hidden_size, output_size).to(\"cuda\")\n",
        "# model = FF_2Network(input_size, hidden_size, output_size).to(\"cuda\")\n",
        "# model = GaussianNetwork(input_size, hidden_size, output_size).to(\"cuda\")\n",
        "model = TransformerRegressor(input_size).to(\"cuda\")\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "# criterion = nn.GaussianNLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=max_lr)\n",
        "\n",
        "# Implement One Cycle LR\n",
        "steps_per_epoch = len(train_loader)\n",
        "total_train_steps = num_epochs * steps_per_epoch\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, \n",
        "                                                total_steps=total_train_steps,\n",
        "                                                pct_start=0.1, anneal_strategy='cos',\n",
        "                                                cycle_momentum=True, base_momentum=0.85,\n",
        "                                                max_momentum=0.95, div_factor=25.0,\n",
        "                                                final_div_factor=10000.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hLwfcGROagC",
        "outputId": "d6643fee-9133-485e-bb83-e54173c2ddf6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:x0kb7892) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>▁▂▄▆█</td></tr><tr><td>total_steps</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▄▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.00011</td></tr><tr><td>total_steps</td><td>500</td></tr><tr><td>train_loss</td><td>0.10578</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vivid-spaceship-34</strong> at: <a href='https://wandb.ai/michaelliangaus/auroral-precipitation-ml/runs/x0kb7892' target=\"_blank\">https://wandb.ai/michaelliangaus/auroral-precipitation-ml/runs/x0kb7892</a><br/> View project at: <a href='https://wandb.ai/michaelliangaus/auroral-precipitation-ml' target=\"_blank\">https://wandb.ai/michaelliangaus/auroral-precipitation-ml</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240924_235359-x0kb7892/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:x0kb7892). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.18.1 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/michael/auroral-precipitation-ml/wandb/run-20240924_235527-1zvm53m4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/michaelliangaus/auroral-precipitation-ml/runs/1zvm53m4' target=\"_blank\">crimson-wind-35</a></strong> to <a href='https://wandb.ai/michaelliangaus/auroral-precipitation-ml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/michaelliangaus/auroral-precipitation-ml' target=\"_blank\">https://wandb.ai/michaelliangaus/auroral-precipitation-ml</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/michaelliangaus/auroral-precipitation-ml/runs/1zvm53m4' target=\"_blank\">https://wandb.ai/michaelliangaus/auroral-precipitation-ml/runs/1zvm53m4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 825/4107 [01:59<08:04,  6.77it/s]"
          ]
        }
      ],
      "source": [
        "# Initialize wandb run\n",
        "wandb.init(\n",
        "    project=\"auroral-precipitation-ml\",\n",
        "    config={\n",
        "        \"dataset_size\": len(train_df),\n",
        "        \"validation_size\": len(eval_df),\n",
        "        \"columns\": columns_to_keep\n",
        "    }\n",
        ")\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(data_loader):\n",
        "            x = x.to(\"cuda\")\n",
        "            y = y.to(\"cuda\")\n",
        "            if model.__class__.__name__ == 'GaussianNetwork':\n",
        "                y_pred, var = model(x)\n",
        "                loss = criterion(y_pred, y, var)\n",
        "            else:\n",
        "                y_pred = model(x)\n",
        "                loss = criterion(y_pred, y)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "# Training loop\n",
        "eval_every = 1\n",
        "log_every_step = 100\n",
        "\n",
        "total_steps = 0\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    for i, (x, y) in enumerate(tqdm(train_loader)):\n",
        "        x = x.to(\"cuda\")\n",
        "        y = y.to(\"cuda\")\n",
        "\n",
        "        # Forward pass\n",
        "        if model.__class__.__name__ == 'GaussianNetwork':\n",
        "            y_pred, var = model(x)\n",
        "            loss = criterion(y_pred, y, var)\n",
        "        else:\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred, y)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        total_steps += 1\n",
        "\n",
        "        # Log train loss and learning rate every log_every_step iterations\n",
        "        if total_steps % log_every_step == 0:\n",
        "            wandb.log({\n",
        "                \"train_loss\": loss.item(),\n",
        "                \"learning_rate\": scheduler.get_last_lr()[0],\n",
        "                \"total_steps\": total_steps\n",
        "            })\n",
        "\n",
        "    avg_train_loss = epoch_loss / len(train_loader)\n",
        "    test_loss = evaluate_model(model, eval_loader, criterion)\n",
        "    \n",
        "    # Log train and test loss to wandb\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch,\n",
        "        \"test_loss\": test_loss\n",
        "    })\n",
        "    if (epoch + 1) % eval_every == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Avg Train Loss: {avg_train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
        "\n",
        "print('Training finished!')\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), f'{model_name}.pth')\n",
        "\n",
        "# Final evaluation\n",
        "final_test_loss = evaluate_model(model, eval_loader, criterion)\n",
        "print(f'Final Test Loss: {final_test_loss:.4f}')\n",
        "wandb.log({\"final_test_loss\": final_test_loss}) # 0.0314"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fovbv-QcPC-2",
        "outputId": "45c77601-257a-4ef4-c4c1-5a525350e0e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_349632/2431572813.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('models/tf_1/tf_1.pth'))\n",
            "Evaluating: 100%|██████████| 100000/100000 [03:08<00:00, 531.28it/s]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on the test set\n",
        "# # Gaussian Network gaussian_1\n",
        "# input_size = len(input_columns)\n",
        "# hidden_size = 256\n",
        "# model = GaussianNetwork(input_size, hidden_size, output_size).to(\"cuda\")\n",
        "# model.load_state_dict(torch.load('models/gaussian_1/gaussian_1.pth'))\n",
        "\n",
        "# FF Network ff_1\n",
        "# input_size = len(input_columns)\n",
        "# hidden_size = 256\n",
        "# model = Network(input_size, hidden_size, output_size).to(\"cuda\")\n",
        "# model.load_state_dict(torch.load('models/ff_1/ff_1.pth'))\n",
        "\n",
        "# FF Network ff_2\n",
        "# model = FF_2Network(input_size, hidden_size, output_size).to(\"cuda\")\n",
        "# model.load_state_dict(torch.load('ff_2.pth'))\n",
        "\n",
        "# Transformer Regressor tf_1\n",
        "model = TransformerRegressor(input_size).to(\"cuda\")\n",
        "model.load_state_dict(torch.load('models/tf_1/tf_1.pth'))\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "test_df = pd.read_csv('data/test.tsv', sep='\\t')\n",
        "test_df = test_df[columns_to_keep]\n",
        "test_df['DateFormatted'] = pd.to_datetime(test_df['DateFormatted'] + ' ' + test_df['TimeFormatted'], format='%Y-%m-%d %H:%M:%S')\n",
        "test_df.drop('TimeFormatted', axis=1, inplace=True)\n",
        "test_df_norm = normalize_df(test_df, means, stds, columns_to_normalize)\n",
        "\n",
        "# Convert date/time into cyclic features for test dataset\n",
        "# Extract components from DateFormatted\n",
        "test_df_norm['Year'] = test_df_norm['DateFormatted'].dt.year - 1989\n",
        "test_df_norm['DayOfYear'] = test_df_norm['DateFormatted'].dt.dayofyear\n",
        "test_df_norm['TimeOfDay'] = (test_df_norm['DateFormatted'].dt.hour * 3600 +\n",
        "                             test_df_norm['DateFormatted'].dt.minute * 60 +\n",
        "                             test_df_norm['DateFormatted'].dt.second) / 86400\n",
        "\n",
        "# Calculate cyclic features\n",
        "test_df_norm['DayOfYear_sin'] = np.sin(2 * np.pi * test_df_norm['DayOfYear'] / 365.25)\n",
        "test_df_norm['TimeOfDay_sin'] = np.sin(2 * np.pi * test_df_norm['TimeOfDay'])\n",
        "test_df_norm_final = test_df_norm.drop(['DateFormatted', 'DayOfYear', 'TimeOfDay'], axis=1)\n",
        "\n",
        "test_ds = DataFrameDataset(test_df_norm_final, input_columns, output_column)\n",
        "\n",
        "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0)\n",
        "\n",
        "target_mean = means[output_column]\n",
        "target_std = stds[output_column]\n",
        "\n",
        "def unnormalize_mean(pred, target_mean, target_std):\n",
        "    return pred * target_std + target_mean\n",
        "\n",
        "def unnormalize_var(var, target_std):\n",
        "    return var * (target_std ** 2)\n",
        "\n",
        "correct_predictions = 0\n",
        "total_samples = len(test_loader)\n",
        "predictions = []\n",
        "true_values = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        x = x.to(\"cuda\")\n",
        "        y = y.to(\"cuda\")\n",
        "        \n",
        "        # Forward pass\n",
        "        if model.__class__.__name__ == 'GaussianNetwork':\n",
        "            y_pred, var = model(x)\n",
        "        else:\n",
        "            y_pred = model(x)\n",
        "        \n",
        "        # Unnormalize predictions and true values\n",
        "        y_true = unnormalize_mean(y.cpu().item(), target_mean, target_std)\n",
        "        y_pred = unnormalize_mean(y_pred.cpu().item(), target_mean, target_std)\n",
        "        # var_pred = unnormalize_var(var.cpu().item(), target_std) # Not used but could be useful for uncertainty quantification\n",
        "        \n",
        "        predictions.append(y_pred)\n",
        "        true_values.append(y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate deviations\n",
        "deviations = [pred - true for pred, true in zip(predictions, true_values)]\n",
        "\n",
        "# Calculate percentages within specified absolute deviations\n",
        "thresholds = [100, 200, 300, 500, 1000, 2000, 5000]\n",
        "percentages = [\n",
        "    sum(abs(dev) <= threshold for dev in deviations) / len(deviations) * 100\n",
        "    for threshold in thresholds\n",
        "]\n",
        "\n",
        "# Calculate percentages within specified relative deviations\n",
        "relative_thresholds = [5, 10, 15, 20]\n",
        "relative_percentages = [\n",
        "    sum(abs(dev) / true * 100 <= threshold for dev, true in zip(deviations, true_values)) / len(deviations) * 100\n",
        "    for threshold in relative_thresholds\n",
        "]\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.hist(deviations, bins=50, edgecolor='black')\n",
        "plt.xlabel('Deviation from Ground Truth')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Model Predictions Deviation')\n",
        "\n",
        "# Add text box with percentages\n",
        "text = \"\\n\".join([\n",
        "    f\"Within {threshold}: {percentage:.2f}%\"\n",
        "    for threshold, percentage in zip(thresholds, percentages)\n",
        "] + [\"\\n\"] + [  # Add an empty line between absolute and relative thresholds\n",
        "    f\"Within {threshold}%: {percentage:.2f}%\"\n",
        "    for threshold, percentage in zip(relative_thresholds, relative_percentages)\n",
        "])\n",
        "plt.text(0.95, 0.95, text, transform=plt.gca().transAxes, \n",
        "         verticalalignment='top', horizontalalignment='right',\n",
        "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig('deviation.png')\n",
        "plt.close()  # Close the figure to free up memory"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
